{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import data_utils\n",
    "import download\n",
    "from scipy.stats import skew, kurtosis\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from keras import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path):\n",
    "    listOfTestFiles = os.listdir(path=path)\n",
    "    train = []\n",
    "    train_labels = []\n",
    "    test = []\n",
    "    test_labels = []\n",
    "        \n",
    "        \n",
    "    print(\"Training files = \",listOfTestFiles[1:6])\n",
    "    #For collecting Training data:\n",
    "    for file in listOfTestFiles[1:6]:\n",
    "        with open(path+file,'rb') as fo:\n",
    "            dict = pickle.load(fo,encoding='bytes')\n",
    "            train.append(dict[b'data'])\n",
    "            train_labels.append(dict[b'labels'])\n",
    "\n",
    "    print(listOfTestFiles[7])\n",
    "    #for collecting Testing data\n",
    "    with open(path+listOfTestFiles[7],'rb') as fo:\n",
    "            dict = pickle.load(fo,encoding='bytes')\n",
    "            test.append(dict[b'data'])\n",
    "            test_labels.append(dict[b'labels'])\n",
    "\n",
    "    dictData = {}\n",
    "    dictData['train_data'] = np.reshape(np.array(train),newshape=(np.array(train).shape[0]*np.array(train).shape[1],np.array(train).shape[2]))\n",
    "    dictData['train_labels'] = np.reshape(np.array(train_labels),newshape=(np.array(train_labels).shape[0]*np.array(train_labels).shape[1]))\n",
    "    dictData['test_data'] = np.reshape(np.array(test),newshape=(np.array(test).shape[0]*np.array(test).shape[1],np.array(test).shape[2]))\n",
    "    dictData['test_labels'] = np.reshape(np.array(test_labels),newshape=(np.array(test_labels).shape[0]*np.array(test_labels).shape[1]))\n",
    "    return dictData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNearestNeighbour(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        # Knn will remember all of its training data\n",
    "        self.Xtr = X\n",
    "        self.Ytr = Y\n",
    "        \n",
    "    def predict(self, X, k):\n",
    "        # Ensure k is not larger than the training dataset\n",
    "        if k > self.Xtr.shape[0]:\n",
    "            raise ValueError(f\"k={k} is greater than the number of training samples={self.Xtr.shape[0]}\")\n",
    "        \n",
    "        # Number of test samples\n",
    "        test_samples = X.shape[0]\n",
    "        Ypred = np.zeros(test_samples, dtype=self.Ytr.dtype)\n",
    "        \n",
    "        for i in range(test_samples):\n",
    "            print(f\"Test example = {i}\", end=\"\\r\")\n",
    "            \n",
    "            # Compute L1 distances\n",
    "            dist = np.sum(np.abs(X[i, :] - self.Xtr), axis=1)\n",
    "            \n",
    "            # Find the indices of the k smallest distances\n",
    "            idx = np.argpartition(dist, k)[:k]\n",
    "            \n",
    "            # Initialize weights for each label\n",
    "            label_weights = np.zeros(10, dtype=np.float32)\n",
    "            \n",
    "            for x in idx:\n",
    "                distance = dist[x]\n",
    "                if distance == 0:\n",
    "                    weight = 1e6  # Assign a very high weight if distance is 0 to avoid division by zero\n",
    "                else:\n",
    "                    weight = 1 / distance\n",
    "                \n",
    "                # Accumulate weights for the corresponding label\n",
    "                label_weights[int(self.Ytr[x])] += weight\n",
    "            \n",
    "            # Assign the label with the maximum weighted sum\n",
    "            Ypred[i] = np.argmax(label_weights)\n",
    "        \n",
    "        return Ypred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "assert x_train.shape == (50000, 32, 32, 3)\n",
    "assert x_test.shape == (10000, 32, 32, 3)\n",
    "assert y_train.shape == (50000, 1)\n",
    "assert y_test.shape == (10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Flatten the data\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)  # (50000, 32*32*3)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)    # (10000, 32*32*3)\n",
    "\n",
    "# Reshape labels to 1D\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37 99\n"
     ]
    }
   ],
   "source": [
    "# Initialize the KNN classifier\n",
    "knn = kNearestNeighbour()\n",
    "\n",
    "# Train the classifier\n",
    "knn.train(x_train_flat, y_train)\n",
    "\n",
    "# Predict the labels for a subset of test data (e.g., 100 samples)\n",
    "num_test_samples = 100  # To save time, use a small subset for testing\n",
    "y_pred = knn.predict(x_test_flat[:num_test_samples], k=20)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test[:num_test_samples], y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LDA\n",
    "lda = LinearDiscriminantAnalysis(n_components=9)  # CIFAR-10 has 10 classes, so max components = 10 - 1\n",
    "x_train_lda = lda.fit_transform(x_train_flat, y_train)\n",
    "x_test_lda = lda.transform(x_test_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for k = 1\n",
      "Accuracy for k = 1: 30.00%\n",
      "Testing for k = 2\n",
      "Accuracy for k = 2: 30.00%\n",
      "Testing for k = 3\n",
      "Accuracy for k = 3: 34.00%\n",
      "Testing for k = 4\n",
      "Accuracy for k = 4: 38.00%\n",
      "Testing for k = 5\n",
      "Accuracy for k = 5: 38.00%\n",
      "Testing for k = 6\n",
      "Accuracy for k = 6: 35.00%\n",
      "Testing for k = 7\n",
      "Accuracy for k = 7: 40.00%\n",
      "Testing for k = 8\n",
      "Accuracy for k = 8: 39.00%\n",
      "Testing for k = 9\n",
      "Accuracy for k = 9: 40.00%\n",
      "Testing for k = 10\n",
      "Accuracy for k = 10: 37.00%\n",
      "\n",
      "Summary of accuracies for different k values:\n",
      "k = 1: Accuracy = 30.00%\n",
      "k = 2: Accuracy = 30.00%\n",
      "k = 3: Accuracy = 34.00%\n",
      "k = 4: Accuracy = 38.00%\n",
      "k = 5: Accuracy = 38.00%\n",
      "k = 6: Accuracy = 35.00%\n",
      "k = 7: Accuracy = 40.00%\n",
      "k = 8: Accuracy = 39.00%\n",
      "k = 9: Accuracy = 40.00%\n",
      "k = 10: Accuracy = 37.00%\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier after LDA\n",
    "knn.train(x_train_lda, y_train)\n",
    "k_values = [2, 5, 10, 15, 25, 50]  # Test k from 1 to 10\n",
    "\n",
    "# Store the accuracies for each k\n",
    "accuracies = []\n",
    "\n",
    "# Loop through each k value\n",
    "for k in k_values:\n",
    "    print(f\"Testing for k = {k}\")\n",
    "    \n",
    "    # Predict the labels for a subset of test data\n",
    "    num_test_samples = 100  # To save time, use a small subset for testing\n",
    "    y_pred = knn.predict(x_test_lda[:num_test_samples], k=k)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test[:num_test_samples], y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    # Print accuracy for this k\n",
    "    print(f\"Accuracy for k = {k}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nSummary of accuracies for different k values:\")\n",
    "for k, acc in zip(k_values, accuracies):\n",
    "    print(f\"k = {k}: Accuracy = {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
